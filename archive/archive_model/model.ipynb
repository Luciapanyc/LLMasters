{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2ogpte import H2OGPTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Server version 1.4.10 doesn't match client version 1.4.9: unexpected errors may occur.\n",
      "Please install the correct version of H2OGPTE with `pip install h2ogpte==1.4.10`.\n",
      "You can enable strict version checking by passing strict_version_check=True.\n"
     ]
    }
   ],
   "source": [
    "client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key='sk-yG5q6JxtLgMS1Twv0mwZKbIVmJw5pNKGL6uU57p5IfYYJUq7',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_documents(client: H2OGPTE):\n",
    "    collection_id = None\n",
    "    name = 'Musicrecco'\n",
    "\n",
    "    recent_collections = client.list_recent_collections(0, 1000)\n",
    "    for c in recent_collections:\n",
    "        if c.name == name and c.document_count:\n",
    "            collection_id = c.id\n",
    "            break\n",
    "\n",
    "    # Create Collection\n",
    "    if collection_id is None:\n",
    "        collection_id = client.create_collection(\n",
    "            name=name,\n",
    "            description='Music Recommender',\n",
    "        )\n",
    "\n",
    "        # Upload file into collection\n",
    "        song_data = client.upload('song.xlsx', open('../../data/song.xlsx', 'rb'))\n",
    "        client.ingest_uploads(collection_id, [song_data])\n",
    "\n",
    "        print(f\"DONE: {collection_id}\")\n",
    "    return collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: cf6a560d-433e-4924-8799-2de7aeb2e7c8\n"
     ]
    }
   ],
   "source": [
    "collection_id = ingest_documents(client)\n",
    "chat_session_id = client.create_chat_session(collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INITIAL_WAIT_INTERVAL',\n",
       " 'MAX_WAIT_INTERVAL',\n",
       " 'TIMEOUT',\n",
       " 'WAIT_BACKOFF_FACTOR',\n",
       " 'answer_question',\n",
       " 'cancel_job',\n",
       " 'connect',\n",
       " 'count_assets',\n",
       " 'count_chat_sessions',\n",
       " 'count_chat_sessions_for_collection',\n",
       " 'count_collections',\n",
       " 'count_documents',\n",
       " 'count_documents_in_collection',\n",
       " 'count_documents_owned_by_me',\n",
       " 'count_prompt_templates',\n",
       " 'count_question_reply_feedback',\n",
       " 'create_chat_session',\n",
       " 'create_chat_session_on_default_collection',\n",
       " 'create_collection',\n",
       " 'create_prompt_template',\n",
       " 'delete_chat_messages',\n",
       " 'delete_chat_sessions',\n",
       " 'delete_collections',\n",
       " 'delete_document_summaries',\n",
       " 'delete_documents',\n",
       " 'delete_documents_from_collection',\n",
       " 'delete_prompt_templates',\n",
       " 'delete_upload',\n",
       " 'download_document',\n",
       " 'encode_for_retrieval',\n",
       " 'extract_data',\n",
       " 'get_chat_session_prompt_template',\n",
       " 'get_chat_session_questions',\n",
       " 'get_chunks',\n",
       " 'get_collection',\n",
       " 'get_collection_for_chat_session',\n",
       " 'get_collection_prompt_template',\n",
       " 'get_collection_questions',\n",
       " 'get_default_collection',\n",
       " 'get_document',\n",
       " 'get_job',\n",
       " 'get_llm_names',\n",
       " 'get_llm_usage_24h',\n",
       " 'get_llm_usage_24h_by_llm',\n",
       " 'get_llm_usage_24h_with_limits',\n",
       " 'get_llm_usage_6h',\n",
       " 'get_llm_usage_6h_by_llm',\n",
       " 'get_llm_usage_by_llm',\n",
       " 'get_llm_usage_with_limits',\n",
       " 'get_llms',\n",
       " 'get_meta',\n",
       " 'get_prompt_template',\n",
       " 'get_scheduler_stats',\n",
       " 'import_collection_into_collection',\n",
       " 'import_document_into_collection',\n",
       " 'ingest_from_file_system',\n",
       " 'ingest_uploads',\n",
       " 'ingest_website',\n",
       " 'list_chat_message_meta_part',\n",
       " 'list_chat_message_references',\n",
       " 'list_chat_messages',\n",
       " 'list_chat_messages_full',\n",
       " 'list_chat_sessions_for_collection',\n",
       " 'list_collection_permissions',\n",
       " 'list_collections_for_document',\n",
       " 'list_documents_in_collection',\n",
       " 'list_embedding_models',\n",
       " 'list_jobs',\n",
       " 'list_list_chat_message_meta',\n",
       " 'list_question_reply_feedback_data',\n",
       " 'list_recent_chat_sessions',\n",
       " 'list_recent_collections',\n",
       " 'list_recent_collections_sort',\n",
       " 'list_recent_document_summaries',\n",
       " 'list_recent_documents',\n",
       " 'list_recent_documents_with_summaries',\n",
       " 'list_recent_documents_with_summaries_sort',\n",
       " 'list_recent_prompt_templates',\n",
       " 'list_recent_prompt_templates_sort',\n",
       " 'list_upload',\n",
       " 'list_users',\n",
       " 'make_collection_private',\n",
       " 'make_collection_public',\n",
       " 'match_chunks',\n",
       " 'reset_collection_prompt_settings',\n",
       " 'search_chunks',\n",
       " 'set_chat_message_votes',\n",
       " 'set_chat_session_prompt_template',\n",
       " 'set_collection_prompt_template',\n",
       " 'share_collection',\n",
       " 'summarize_content',\n",
       " 'summarize_document',\n",
       " 'unshare_collection',\n",
       " 'unshare_collection_for_all',\n",
       " 'update_collection',\n",
       " 'update_collection_rag_type',\n",
       " 'update_prompt_template',\n",
       " 'upload']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(client) if x[:1] != \"_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mistralai/Mixtral-8x7B-Instruct-v0.1', 'h2oai/h2ogpt-4096-llama2-70b-chat', 'h2oai/h2ogpt-4096-llama2-13b-chat', 'h2oai/h2ogpt-32k-codellama-34b-instruct', 'HuggingFaceH4/zephyr-7b-beta', 'NousResearch/Nous-Capybara-34B', 'claude-2.1', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-16k-0613', 'gpt-35-turbo-1106', 'gpt-4-1106-preview', 'gemini-pro', 'mistral-small-latest', 'mistral-large-latest', 'mistral-medium']\n"
     ]
    }
   ],
   "source": [
    "print([x[\"base_model\"] for x in client.get_llms()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(is_default=True, id=None, name='Defaults', description='Default h2oGPTe prompt template', lang='en', system_prompt='You are h2oGPTe, an expert question-answering AI system created by H2O.ai that performs like GPT-4 by OpenAI.', pre_prompt_query='Pay attention and remember the information below. You will need to use only the given document context to answer the question or imperative at the end.', prompt_query='According to only the information in the document sources provided within the context above, ', hyde_no_rag_llm_prompt_extension='Keep the answer brief, and list the 5 most relevant key words at the end.', pre_prompt_summary='In order to write a concise single-paragraph or bulleted list summary, pay attention to the following text:', prompt_summary='Using only the text above, write a condensed and concise summary of key results (preferably as bullet points).', system_prompt_reflection='You are acting as a judge. You must be fair and impartial and pay attention to details.', pre_prompt_reflection='', prompt_reflection='Review the user\\'s question and the corresponding response using the additive 5-point scoring system described below. Points are accumulated based on the satisfaction of each criterion:\\n\\n- Add 1 point if the response is relevant and provides some information related to the user\\'s inquiry, even if it is incomplete or contains some irrelevant content.\\n- Add another point if the response addresses a substantial portion of the user\\'s question, but does not completely resolve the query or provide a direct answer.\\n- Award a third point if the response answers the basic elements of the user\\'s question in a useful way, regardless of whether it seems to have been written by an AI Assistant or if it has elements typically found in blogs or search results.\\n- Grant a fourth point if the response is clearly written from an AI Assistant\\'s perspective, addressing the user\\'s question directly and comprehensively, and is well-organized and helpful, even if there is slight room for improvement in clarity, conciseness or focus.\\n- Bestow a fifth point for a response that is impeccably tailored to the user\\'s question by an AI Assistant, without extraneous information, reflecting expert knowledge, and demonstrating a high-quality, engaging, and insightful answer.\\n\\n<user>\\n%s\\n</user>\\n\\n<response>\\n%s\\n</response>\\n\\nAfter examining the user\\'s instruction and the response:\\n\\n- Briefly justify your total score, up to 100 words.\\n- Conclude with the score using the format: \"Score: <total points> / 5\"\\n\\nRemember to assess from the AI Assistant perspective, utilizing web search knowledge as necessary. To evaluate the response in alignment with this additive scoring model, we\\'ll systematically attribute points based on the outlined criteria.\\n', auto_gen_description_prompt='Create a short one-sentence summary from the above context, with the goal to make it clear to the reader what this is about.', auto_gen_document_summary_pre_prompt_summary='In order to write a concise single-paragraph summary, pay attention to the following text:', auto_gen_document_summary_prompt_summary='Using only the text above, write a condensed and concise summary of key results (preferably as one paragraph).', auto_gen_document_sample_questions_prompt='Create 10 interesting questions for which the answers are contained in the information provided above. Respond in JSON, like this: {{\"q1\": \"Question 1?\", \"q2\": \"Question 2?\", ..., \"q10\": \"Question 10?\"}}.', default_sample_questions=['Create five good questions', 'Summarize in one sentence', 'Explain this to a 5-year old', 'Tell me something interesting'], created_at=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = 'rock,pop,country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"You are an AI chatbot that reccommend songs base on user message. You take in query and find similar songs base on favourite genre and listening history of user which can be found in listening_history.xlsx by userid provided. You must reccommend songs in the song.xlsx, a file contains data with columns for Spotify ID, Song name, Artist, Rank, Genre, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. And you must return song name in double quotation, artist name in brackets, along with spotify id. Must return song name, song artist and spotify id.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_id = client.create_prompt_template(\n",
    "    name=\"Song Recommendation Template\",\n",
    "    description=\"Template for recommending songs\",\n",
    "    system_prompt = \"You are an AI chatbot that reccommend songs base on user message. You take in query and find similar songs base on favourite genre and listening history of user which can be found in listening_history.xlsx by userid provided. You must reccommend songs in the song.xlsx, a file contains data with columns for Spotify ID, Song name, Artist, Rank, Genre, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. And you must return song name in double quotation, artist name in brackets, along with spotify id. Must return song name, song artist and spotify id.\",\n",
    "    pre_prompt_query=\"Before providing recommendations, please provide your favorite music genre and userid.\",\n",
    "    prompt_query=\"Reccommend me a max of 5 songs based on my favourite genre with spotify id that is not in my lsitening history.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cf6a560d-433e-4924-8799-2de7aeb2e7c8'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set_collection_prompt_template(collection_id, prompt_template_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(is_default=False, id='83b6014e-a970-4dae-9b2b-e99e7cf0dd3b', name='Song Recommendation Template', description='Template for recommending songs', lang=None, system_prompt='You are an AI chatbot that reccommend songs base on user message. You take in query and find similar songs base on favourite genre and listening history of user which can be found in listening_history.xlsx by userid provided. You must reccommend songs in the song.xlsx, a file contains data with columns for Spotify ID, Song name, Artist, Rank, Genre, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. And you must return song name in double quotation, artist name in brackets, along with spotify id. Must return song name, song artist and spotify id.', pre_prompt_query='Before providing recommendations, please provide your favorite music genre and userid.', prompt_query='Reccommend me a max of 5 songs based on my favourite genre with spotify id that is not in my lsitening history.', hyde_no_rag_llm_prompt_extension=None, pre_prompt_summary=None, prompt_summary=None, system_prompt_reflection=None, pre_prompt_reflection=None, prompt_reflection=None, auto_gen_description_prompt=None, auto_gen_document_summary_pre_prompt_summary=None, auto_gen_document_summary_prompt_summary=None, auto_gen_document_sample_questions_prompt=None, default_sample_questions=None, created_at=datetime.datetime(2024, 4, 12, 18, 8, 37, 705050, tzinfo=TzInfo(UTC)))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_chat_session_prompt_template(chat_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your preference for pop music and request for dance songs, here are three song recommendations with their Spotify IDs:\n",
      "\n",
      "1. \"Work From Home\" by Fifth Harmony - 6UkMcAA19lTdjs22jtB7o2\n",
      "2. \"Can't Stop The Feeling!\" by Justin Timberlake - 48no41hFQ2y0I4vDGjPPeC\n",
      "3. \"Worth It\" by Fifth Harmony - 5vPRCX0Bj8O374jTCAQRLS\n",
      "\n",
      "These songs have high energy and danceability scores, making them great choices for dancing. Enjoy listening!\n"
     ]
    }
   ],
   "source": [
    "with client.connect(chat_session_id) as session:\n",
    "    answer = session.query(\n",
    "        message=\"I like pop give me 3 dance songs\",\n",
    "        rag_config={\"rag_type\": \"rag\"},\n",
    "    ).content\n",
    "\n",
    "    print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
