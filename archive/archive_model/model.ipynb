{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2ogpte import H2OGPTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Server version 1.4.10 doesn't match client version 1.4.9: unexpected errors may occur.\n",
      "Please install the correct version of H2OGPTE with `pip install h2ogpte==1.4.10`.\n",
      "You can enable strict version checking by passing strict_version_check=True.\n"
     ]
    }
   ],
   "source": [
    "client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key='sk-yG5q6JxtLgMS1Twv0mwZKbIVmJw5pNKGL6uU57p5IfYYJUq7',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_documents(client: H2OGPTE):\n",
    "    collection_id = None\n",
    "    name = 'Musicrecco'\n",
    "\n",
    "    recent_collections = client.list_recent_collections(0, 1000)\n",
    "    for c in recent_collections:\n",
    "        if c.name == name and c.document_count:\n",
    "            collection_id = c.id\n",
    "            break\n",
    "\n",
    "    # Create Collection\n",
    "    if collection_id is None:\n",
    "        collection_id = client.create_collection(\n",
    "            name=name,\n",
    "            description='Music Recommender',\n",
    "        )\n",
    "\n",
    "        # Upload file into collection\n",
    "        song_data = client.upload('song.xlsx', open('../../data/song.xlsx', 'rb'))\n",
    "        client.ingest_uploads(collection_id, [song_data])\n",
    "\n",
    "        print(f\"DONE: {collection_id}\")\n",
    "    return collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = ingest_documents(client)\n",
    "chat_session_id = client.create_chat_session(collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INITIAL_WAIT_INTERVAL',\n",
       " 'MAX_WAIT_INTERVAL',\n",
       " 'TIMEOUT',\n",
       " 'WAIT_BACKOFF_FACTOR',\n",
       " 'answer_question',\n",
       " 'cancel_job',\n",
       " 'connect',\n",
       " 'count_assets',\n",
       " 'count_chat_sessions',\n",
       " 'count_chat_sessions_for_collection',\n",
       " 'count_collections',\n",
       " 'count_documents',\n",
       " 'count_documents_in_collection',\n",
       " 'count_documents_owned_by_me',\n",
       " 'count_prompt_templates',\n",
       " 'count_question_reply_feedback',\n",
       " 'create_chat_session',\n",
       " 'create_chat_session_on_default_collection',\n",
       " 'create_collection',\n",
       " 'create_prompt_template',\n",
       " 'delete_chat_messages',\n",
       " 'delete_chat_sessions',\n",
       " 'delete_collections',\n",
       " 'delete_document_summaries',\n",
       " 'delete_documents',\n",
       " 'delete_documents_from_collection',\n",
       " 'delete_prompt_templates',\n",
       " 'delete_upload',\n",
       " 'download_document',\n",
       " 'encode_for_retrieval',\n",
       " 'extract_data',\n",
       " 'get_chat_session_prompt_template',\n",
       " 'get_chat_session_questions',\n",
       " 'get_chunks',\n",
       " 'get_collection',\n",
       " 'get_collection_for_chat_session',\n",
       " 'get_collection_prompt_template',\n",
       " 'get_collection_questions',\n",
       " 'get_default_collection',\n",
       " 'get_document',\n",
       " 'get_job',\n",
       " 'get_llm_names',\n",
       " 'get_llm_usage_24h',\n",
       " 'get_llm_usage_24h_by_llm',\n",
       " 'get_llm_usage_24h_with_limits',\n",
       " 'get_llm_usage_6h',\n",
       " 'get_llm_usage_6h_by_llm',\n",
       " 'get_llm_usage_by_llm',\n",
       " 'get_llm_usage_with_limits',\n",
       " 'get_llms',\n",
       " 'get_meta',\n",
       " 'get_prompt_template',\n",
       " 'get_scheduler_stats',\n",
       " 'import_collection_into_collection',\n",
       " 'import_document_into_collection',\n",
       " 'ingest_from_file_system',\n",
       " 'ingest_uploads',\n",
       " 'ingest_website',\n",
       " 'list_chat_message_meta_part',\n",
       " 'list_chat_message_references',\n",
       " 'list_chat_messages',\n",
       " 'list_chat_messages_full',\n",
       " 'list_chat_sessions_for_collection',\n",
       " 'list_collection_permissions',\n",
       " 'list_collections_for_document',\n",
       " 'list_documents_in_collection',\n",
       " 'list_embedding_models',\n",
       " 'list_jobs',\n",
       " 'list_list_chat_message_meta',\n",
       " 'list_question_reply_feedback_data',\n",
       " 'list_recent_chat_sessions',\n",
       " 'list_recent_collections',\n",
       " 'list_recent_collections_sort',\n",
       " 'list_recent_document_summaries',\n",
       " 'list_recent_documents',\n",
       " 'list_recent_documents_with_summaries',\n",
       " 'list_recent_documents_with_summaries_sort',\n",
       " 'list_recent_prompt_templates',\n",
       " 'list_recent_prompt_templates_sort',\n",
       " 'list_upload',\n",
       " 'list_users',\n",
       " 'make_collection_private',\n",
       " 'make_collection_public',\n",
       " 'match_chunks',\n",
       " 'reset_collection_prompt_settings',\n",
       " 'search_chunks',\n",
       " 'set_chat_message_votes',\n",
       " 'set_chat_session_prompt_template',\n",
       " 'set_collection_prompt_template',\n",
       " 'share_collection',\n",
       " 'summarize_content',\n",
       " 'summarize_document',\n",
       " 'unshare_collection',\n",
       " 'unshare_collection_for_all',\n",
       " 'update_collection',\n",
       " 'update_collection_rag_type',\n",
       " 'update_prompt_template',\n",
       " 'upload']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(client) if x[:1] != \"_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mistralai/Mixtral-8x7B-Instruct-v0.1', 'h2oai/h2ogpt-4096-llama2-70b-chat', 'h2oai/h2ogpt-4096-llama2-13b-chat', 'h2oai/h2ogpt-32k-codellama-34b-instruct', 'HuggingFaceH4/zephyr-7b-beta', 'NousResearch/Nous-Capybara-34B', 'claude-2.1', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-16k-0613', 'gpt-35-turbo-1106', 'gpt-4-1106-preview', 'gemini-pro', 'mistral-small-latest', 'mistral-large-latest', 'mistral-medium']\n"
     ]
    }
   ],
   "source": [
    "print([x[\"base_model\"] for x in client.get_llms()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(is_default=True, id=None, name='Defaults', description='Default h2oGPTe prompt template', lang='en', system_prompt='You are h2oGPTe, an expert question-answering AI system created by H2O.ai that performs like GPT-4 by OpenAI.', pre_prompt_query='Pay attention and remember the information below. You will need to use only the given document context to answer the question or imperative at the end.', prompt_query='According to only the information in the document sources provided within the context above, ', hyde_no_rag_llm_prompt_extension='Keep the answer brief, and list the 5 most relevant key words at the end.', pre_prompt_summary='In order to write a concise single-paragraph or bulleted list summary, pay attention to the following text:', prompt_summary='Using only the text above, write a condensed and concise summary of key results (preferably as bullet points).', system_prompt_reflection='You are acting as a judge. You must be fair and impartial and pay attention to details.', pre_prompt_reflection='', prompt_reflection='Review the user\\'s question and the corresponding response using the additive 5-point scoring system described below. Points are accumulated based on the satisfaction of each criterion:\\n\\n- Add 1 point if the response is relevant and provides some information related to the user\\'s inquiry, even if it is incomplete or contains some irrelevant content.\\n- Add another point if the response addresses a substantial portion of the user\\'s question, but does not completely resolve the query or provide a direct answer.\\n- Award a third point if the response answers the basic elements of the user\\'s question in a useful way, regardless of whether it seems to have been written by an AI Assistant or if it has elements typically found in blogs or search results.\\n- Grant a fourth point if the response is clearly written from an AI Assistant\\'s perspective, addressing the user\\'s question directly and comprehensively, and is well-organized and helpful, even if there is slight room for improvement in clarity, conciseness or focus.\\n- Bestow a fifth point for a response that is impeccably tailored to the user\\'s question by an AI Assistant, without extraneous information, reflecting expert knowledge, and demonstrating a high-quality, engaging, and insightful answer.\\n\\n<user>\\n%s\\n</user>\\n\\n<response>\\n%s\\n</response>\\n\\nAfter examining the user\\'s instruction and the response:\\n\\n- Briefly justify your total score, up to 100 words.\\n- Conclude with the score using the format: \"Score: <total points> / 5\"\\n\\nRemember to assess from the AI Assistant perspective, utilizing web search knowledge as necessary. To evaluate the response in alignment with this additive scoring model, we\\'ll systematically attribute points based on the outlined criteria.\\n', auto_gen_description_prompt='Create a short one-sentence summary from the above context, with the goal to make it clear to the reader what this is about.', auto_gen_document_summary_pre_prompt_summary='In order to write a concise single-paragraph summary, pay attention to the following text:', auto_gen_document_summary_prompt_summary='Using only the text above, write a condensed and concise summary of key results (preferably as one paragraph).', auto_gen_document_sample_questions_prompt='Create 10 interesting questions for which the answers are contained in the information provided above. Respond in JSON, like this: {{\"q1\": \"Question 1?\", \"q2\": \"Question 2?\", ..., \"q10\": \"Question 10?\"}}.', default_sample_questions=['Create five good questions', 'Summarize in one sentence', 'Explain this to a 5-year old', 'Tell me something interesting'], created_at=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = 'rock,pop,country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"As an AI chatbot, you recommend songs based on user queries. You will first analyze the user's favorite genre and listening history, which can be accessed in the listening_history.xlsx file using the provided user ID. Then, you will match these preferences with similar songs from the song.xlsx file. This file includes data on Spotify ID, Song name, Artist, Rank, Genre, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. When recommending songs, you must provide the song name within double quotation marks, the artist name, and the Spotify ID that is a 22 alphanumeric word.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_id = client.create_prompt_template(\n",
    "    name=\"Song Recommendation Template\",\n",
    "    description=\"Template for recommending songs\",\n",
    "    system_prompt = prompt,\n",
    "    pre_prompt_query=\"Before providing recommendations, please provide your favorite music genre and userid.\",\n",
    "    prompt_query=\"Reccommend me a max of 5 songs based on my favourite genre with spotify id that is not in my lsitening history.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'356147d7-f116-439e-9aab-90fcf8726c67'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set_collection_prompt_template(collection_id, prompt_template_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(is_default=False, id='f66d35a0-1049-4a46-8245-fea00415b200', name='Song Recommendation Template', description='Template for recommending songs', lang=None, system_prompt=\"As an AI chatbot, you recommend songs based on user queries. You will first analyze the user's favorite genre and listening history, which can be accessed in the listening_history.xlsx file using the provided user ID. Then, you will match these preferences with similar songs from the song.xlsx file. This file includes data on Spotify ID, Song name, Artist, Rank, Genre, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. When recommending songs, you must provide the song name within double quotation marks, the artist name, and the Spotify ID that is a 22 alphanumeric word.\", pre_prompt_query='Before providing recommendations, please provide your favorite music genre and userid.', prompt_query='Reccommend me a max of 5 songs based on my favourite genre with spotify id that is not in my lsitening history.', hyde_no_rag_llm_prompt_extension=None, pre_prompt_summary=None, prompt_summary=None, system_prompt_reflection=None, pre_prompt_reflection=None, prompt_reflection=None, auto_gen_description_prompt=None, auto_gen_document_summary_pre_prompt_summary=None, auto_gen_document_summary_prompt_summary=None, auto_gen_document_sample_questions_prompt=None, default_sample_questions=None, created_at=datetime.datetime(2024, 4, 12, 18, 54, 39, 752093, tzinfo=TzInfo(UTC)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_chat_session_prompt_template(chat_session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your preference for dance music, here are five song recommendations with their Spotify IDs that are not in your listening history:\n",
      "\n",
      "1. \"Get Lucky\" by Daft Punk (Spotify ID: 6rqhFgbbKwnb9MLmUQDhBI)\n",
      "2. \"Don't Stop the Music\" by Rihanna (Spotify ID: 4cO5pRvC5z6UQiYOuTqo4C)\n",
      "3. \"One More Time\" by Daft Punk (Spotify ID: 6rqhFgbbKwnb9MLmUQDhBI)\n",
      "4. \"Clarity\" by Zedd ft. Foxes (Spotify ID: 5vIuDIiXz2sRoQ0AXq84aI)\n",
      "5. \"Titanium\" by David Guetta ft. Sia (Spotify ID: 6rqhFgbbKwnb9MLmUQDhBI)\n",
      "\n",
      "These songs have high danceability scores and are popular choices in the dance music genre. Enjoy listening!\n"
     ]
    }
   ],
   "source": [
    "with client.connect(chat_session_id) as session:\n",
    "    answer = session.query(\n",
    "        message=\"Some dance songs\",\n",
    "        rag_config={\"rag_type\": \"rag\"},\n",
    "    ).content\n",
    "\n",
    "    print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
