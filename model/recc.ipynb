{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2ogpte import H2OGPTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job(id='6f889932-3ff9-46f9-a972-1dd98a7b9fb6', name='Adding documents', passed=1.0, failed=0.0, progress=1.0, completed=True, canceled=False, date=datetime.datetime(2024, 3, 28, 9, 9, 12, tzinfo=TzInfo(UTC)), kind=<JobKind.IngestUploadsJob: 'IngestUploadsJob'>, statuses=[JobStatus(id='36fea923bf79437c86bd632a60267d92', status='Indexing done.')], errors=[], last_update_date=datetime.datetime(2024, 3, 28, 9, 13, 29, tzinfo=TzInfo(UTC)), duration='4m17s', duration_seconds=257.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = H2OGPTE(\n",
    "    address='https://h2ogpte.genai.h2o.ai',\n",
    "    api_key='sk-ms7SU43E34tS9UJks5RD2KM3m1JumOR2pM73Dk95VzKjM6TZ',\n",
    ")\n",
    "\n",
    "# # Chat with LLM\n",
    "# chat_session_id = client.create_chat_session()\n",
    "# with client.connect(chat_session_id) as session:\n",
    "#     # Simple Question for Document Collection\n",
    "#     answer = session.query(\n",
    "#         \"Can you hallucinate?\",\n",
    "#     ).content\n",
    "#     print(answer)\n",
    "\n",
    "# Create Collection\n",
    "collection_id = client.create_collection(\n",
    "    name=\"MusicRecco\",\n",
    "    description=\"PDF -> text -> summary\",\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Your existing code\n",
    "file_path = \"/Users/blabbyduck/Desktop/Y3S2/DSA4213/LLMasters/data/Cutdown.xlsx\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "     songs = client.upload(os.path.basename(file_path), f)\n",
    "\n",
    "file_path1 = \"/Users/blabbyduck/Desktop/Y3S2/DSA4213/LLMasters/data/listening history.xlsx\"\n",
    "with open(file_path1, \"rb\") as f:\n",
    "     user = client.upload(os.path.basename(file_path1), f)\n",
    "\n",
    "# with open('/Users/blabbyduck/Desktop/Y3S2/DSA4213/LLMasters/data/listening history.xlsx', 'rb') as f:\n",
    "#     hist = client.upload(os.path.basename('/Users/blabbyduck/Desktop/Y3S2/DSA4213/LLMasters/data/listening history.xlsx'), f)\n",
    "\n",
    "# with open('/Users/blabbyduck/Desktop/Y3S2/DSA4213/LLMasters/data/songs_short.xlsx', 'rb') as f:\n",
    "#     songs = client.upload(os.path.basename('/Users/blabbyduck/Desktop/Y3S2/DSA4213/LLMasters/data/songs_short.xlsx'), f)\n",
    "\n",
    "#with open('/Users/blabbyduck/Desktop/Y3S2/DSA4213/LLMasters/data/music.csv', 'rb') as f:\n",
    "#    spot = client.upload(os.path.basename('/Users/blabbyduck/Desktop/Y3S2/DSA4213/LLMasters/data/music.csv'), f)\n",
    "\n",
    "# # Converting the input into chunked text and embeddings...\n",
    "client.ingest_uploads(collection_id, [songs,user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, you have listened to \"All Along the Watchtower\" by Jimi Hendrix, which is a classic rock song. Here are some similar songs that you might enjoy:\n",
      "\n",
      "1. \"Stairway to Heaven\" by Led Zeppelin\n",
      "2. \"More Than a Feeling\" by Boston\n",
      "3. \"Hotel California\" by The Eagles\n",
      "4. \"Sweet Home Alabama\" by Lynyrd Skynyrd\n",
      "5. \"Born to Be Wild\" by Steppenwolf\n",
      "\n",
      "These songs are all considered classics in the rock genre and have a similar sound and feel to \"All Along the Watchtower.\"\n"
     ]
    }
   ],
   "source": [
    "chat_session_id = client.create_chat_session(collection_id)\n",
    "with client.connect(chat_session_id) as session:\n",
    "    # Simple Question for Document Collection\n",
    "        answer = session.query(\n",
    "        message=\"I am user 1. Reccomend me songs similar to my taste\",\n",
    "        system_prompt = 'Assume music and song to be the same word. When a question as for a similar music, recommend less than 5 music unless told otherwise. Find similar music based on genre and other factors such as danceability, loudness, speechiness and more. Just return the song name, unless stated otherwise.' ,\n",
    "        rag_config={\n",
    "            \"rag_type\": \"rag\",\n",
    "        },\n",
    "        ).content\n",
    "        print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mistralai/Mixtral-8x7B-Instruct-v0.1', 'h2oai/h2ogpt-4096-llama2-70b-chat', 'h2oai/h2ogpt-4096-llama2-13b-chat', 'h2oai/h2ogpt-32k-codellama-34b-instruct', 'HuggingFaceH4/zephyr-7b-beta', 'NousResearch/Nous-Capybara-34B', 'claude-2.1', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-16k-0613', 'gpt-35-turbo-1106', 'gpt-4-1106-preview', 'gemini-pro', 'mistral-small-latest', 'mistral-large-latest', 'mistral-medium']\n"
     ]
    }
   ],
   "source": [
    "print([x[\"base_model\"] for x in client.get_llms()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 0\n"
     ]
    }
   ],
   "source": [
    "# Inspect and collect all text chunks\n",
    "chunks = []\n",
    "for chunk_id in range(1, 100):\n",
    "    try:\n",
    "        chunk = client.get_chunks(collection_id, [chunk_id])\n",
    "        print(chunk, flush=True)\n",
    "        chunks.append(chunk[0].text)\n",
    "    except:\n",
    "        break\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_template = \"\"\"\n",
    "Answer the questions based on only the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the questions based on the above context: {query}\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
